{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"colab":{"name":"04_callbacks.ipynb","provenance":[],"collapsed_sections":["AE72dPYXFk7D"]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJXP_5QIFk60","executionInfo":{"status":"ok","timestamp":1620885606246,"user_tz":-540,"elapsed":147773,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"68f0981c-c002-4bdc-bb8a-8db71fa9c319"},"source":["%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","%cd gdrive/MyDrive/Ml/nbs/dl2/\n","\n","from six.moves import urllib\n","opener = urllib.request.build_opener()\n","opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n","urllib.request.install_opener(opener)\n","\n","\n","def get_data():\n","    import os\n","    import torchvision.datasets as datasets\n","    root = '../data'\n","    if not os.path.exists(root):\n","        os.mkdir(root)\n","    train_set = datasets.MNIST(root=root, train=True, download=True)\n","    test_set = datasets.MNIST(root=root, train=False, download=True)\n","    x_train, x_valid = train_set.data.split([50000, 10000])\n","    y_train, y_valid = train_set.targets.split([50000, 10000])\n","    return (x_train.view(50000, -1) / 256.0), y_train.float(), (x_valid.view(10000, -1))/ 256.0, y_valid.float()\n","\n","x_train,y_train,x_valid,y_valid = get_data()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n","/content/gdrive/MyDrive/Ml/nbs/dl2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6tXReoSwFk64"},"source":["#export\n","from exp.nb_03 import *\n","import torchvision"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"41E6duVVFk64"},"source":["## DataBunch/Learner"]},{"cell_type":"markdown","metadata":{"id":"rQwSXs8zFk64"},"source":["[Jump_to lesson 9 video](https://course19.fast.ai/videos/?lesson=9&t=4799)"]},{"cell_type":"code","metadata":{"id":"oeLnlFHUFk64"},"source":["# x_train,y_train,x_valid,y_valid = get_data()\n","\n","train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n","nh,bs = 50,64\n","c = y_train.max().item()+1\n","loss_func = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PEj1NcQNFk65"},"source":["#export\n","class DataBunch():\n","    def __init__(self, train_dl, valid_dl, c=None):\n","        self.train_dl,self.valid_dl,self.c = train_dl,valid_dl,c\n","        \n","        #c is the number of classes\n","    @property\n","    def train_ds(self): return self.train_dl.dataset\n","        \n","    @property\n","    def valid_ds(self): return self.valid_dl.dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzKr0IGFFk65"},"source":["data = DataBunch(*get_dls(train_ds, valid_ds, bs), c)\n","# get_dls is from torch.dataloader\n","# torch dataloader use dataset instead of ds which we studied before with making our own function\n","\n","# def get_dls(train_ds, valid_ds, bs, **kwargs):\n","#     return (DataLoader(train_ds, batch_size=bs, shuffle=True, **kwargs),\n","#             DataLoader(valid_ds, batch_size=bs*2, **kwargs))\n","\n","# c is maximum y value"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"293U1q06GhkC"},"source":["# def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n","#     for epoch in range(epochs):\n","        \n","#         model.train()\n","\n","#         for xb,yb in train_dl:\n","#             loss = loss_func(model(xb), yb)\n","#             loss.backward()\n","#             opt.step()\n","#             opt.zero_grad()\n","\n","#         model.eval()\n","\n","#         with torch.no_grad():\n","#             tot_loss,tot_acc = 0.,0.\n","#             for xb,yb in valid_dl:\n","#                 pred = model(xb)\n","#                 tot_loss += loss_func(pred, yb)\n","#                 tot_acc  += accuracy (pred,yb)\n","#         nv = len(valid_dl)\n","#         print(epoch, tot_loss/nv, tot_acc/nv)\n","#     return tot_loss/nv, tot_acc/nv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3F_avBf0Fk65"},"source":["Factor out the connected pieces of info out of the fit() argument list\n","\n","`fit(epochs, model, loss_func, opt, train_dl, valid_dl)`\n","\n","    ` 1. pass them around to everything that needs them together `\n","\n","    ` 2. create them easily together and look at the combination of them and make smart decision things together`\n","\n","Let's replace it with something that looks like this:\n","\n","`fit(1, learn)`\n","\n","This will allow us to tweak what's happening inside the training loop in other places of the code because the `Learner` object will be mutable, so changing any of its attribute elsewhere will be seen in our training loop."]},{"cell_type":"markdown","metadata":{"id":"rWwKofk6Fk65"},"source":["[Jump_to lesson 9 video](https://course19.fast.ai/videos/?lesson=9&t=5363)"]},{"cell_type":"code","metadata":{"id":"X9wqKwiTFk66"},"source":["#export\n","def get_model(data, lr=0.5, nh=50):\n","    m = data.train_ds.x.shape[1] #size of input\n","\n","    # model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,data.c)) original\n","    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,int(data.c)))\n","    return model, optim.SGD(model.parameters(), lr=lr)\n","\n","class Learner():\n","    def __init__(self, model, opt, loss_func, data):\n","        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data\n","\n","# learner is storage device"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWGeWRfoFk66"},"source":["learn = Learner(*get_model(data), loss_func, data)\n","# we need to fix the error due to different type\n","# data.c is float so we need to change it to int"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MwJ1UGmdFk66"},"source":["def fit(epochs, learn):\n","    for epoch in range(epochs):\n","        learn.model.train()\n","        for xb,yb in learn.data.train_dl:\n","            # print(xb,yb)\n","            loss = learn.loss_func(learn.model(xb), yb.long()) # error arose 바꿔야함\n","            loss.backward()\n","            learn.opt.step()\n","            learn.opt.zero_grad()\n","\n","        learn.model.eval()\n","        with torch.no_grad():\n","            tot_loss,tot_acc = 0,0\n","            for xb,yb in learn.data.valid_dl:\n","                pred = learn.model(xb)\n","                tot_loss += learn.loss_func(pred, yb.long())\n","                tot_acc  += accuracy (pred,yb)\n","        nv = len(learn.data.valid_dl)\n","        print(epoch, tot_loss/nv, tot_acc/nv)\n","    return tot_loss/nv, tot_acc/nv  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uh1am25WFk66","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620313762991,"user_tz":-540,"elapsed":3119,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"6da7dcea-c7db-49bd-d258-bdfa984b291e"},"source":["loss,acc = fit(2, learn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0 tensor(0.2565) tensor(0.9152)\n","1 tensor(0.1452) tensor(0.9578)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nCnPxFtFFk67"},"source":["## Callback"]},{"cell_type":"code","metadata":{"id":"PNlLtu-SKG98"},"source":["# why need callbacks\n","# callback : backward direction - automatic system call the function if condition satistfied.\n","# modify the source code directly is dangerous so we need to use the other way to make events if some condition is satisfied"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBc2lO4bLHIU"},"source":["# 7 images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QVrS1QFJ04S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620147134011,"user_tz":-540,"elapsed":600,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"12644845-04dc-491c-bd85-0294fa1c8d56"},"source":["class test():\n","    def test1(self,in2,in3):\n","        print(in2,in3)\n","        return \n","class inherited_test(test):\n","    def test1(self,in2,in3):\n","        print(in2,in3)\n","        print('moremore')\n","        return\n","\n","test().test1('1','2')\n","print('------')\n","inherited_test().test1('1','2')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1 2\n","------\n","1 2\n","moremore\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SEhqBLtJH259","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"error","timestamp":1620147134552,"user_tz":-540,"elapsed":934,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"6e2100a6-271c-4da5-c719-ba39b3efbfbe"},"source":["# original\n","def fit(epochs, learn):\n","    for epoch in range(epochs):\n","        learn.model.train()\n","        # for xb,yb in learn.data.train_dl:  extract to all batch\n","\n","            # loss = learn.loss_func(learn.model(xb), yb.long())   ====> extract to one batch \n","            # loss.backward()\n","            # learn.opt.step()\n","            # learn.opt.zero_grad()\n","    # why extract and make them fucntion ? -> just make code simple and intuitive by refactoring\n","        learn.model.eval()\n","        with torch.no_grad():\n","        #     tot_loss,tot_acc = 0,0                  ====> also extract to one batch\n","        #     for xb,yb in learn.data.valid_dl:\n","        #         pred = learn.model(xb)\n","        #         tot_loss += learn.loss_func(pred, yb.long())\n","        #         tot_acc  += accuracy (pred,yb)\n","        # nv = len(learn.data.valid_dl)\n","        # print(epoch, tot_loss/nv, tot_acc/nv)\n","    return tot_loss/nv, tot_acc/nv  "],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-a9cebca133ad>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    return tot_loss/nv, tot_acc/nv\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"]}]},{"cell_type":"markdown","metadata":{"id":"dE5dMcacFk67"},"source":["\n","\n","```python\n","def one_batch(xb,yb):\n","    pred = model(xb)\n","    loss = loss_func(pred, yb)\n","    loss.backward()\n","    opt.step()\n","    opt.zero_grad()\n","    \n","def fit():\n","    for epoch in range(epochs):\n","        for b in train_dl: one_batch(*b)\n","```"]},{"cell_type":"markdown","metadata":{"id":"mE7PaoFWFk67"},"source":["Add callbacks so we can remove complexity from loop, and make it flexible:"]},{"cell_type":"markdown","metadata":{"id":"MGBdiAsFFk67"},"source":["[Jump_to lesson 9 video](https://course19.fast.ai/videos/?lesson=9&t=5628)"]},{"cell_type":"code","metadata":{"id":"B0KsKrUIL8W9"},"source":["\n","def one_batch(xb,yb):\n","    #we want to execute some process in ceratin condition here -> maybe stop in certain batch\n","    pred = model(xb)\n","    #we want to execute some process in ceratin condition here -> maybe change the type of preds\n","    loss = loss_func(pred, yb)\n","    #we want to execute some process in ceratin condition here\n","    loss.backward()\n","    #we want to execute some process in ceratin condition here \n","    opt.step()\n","    #we want to execute some process in ceratin condition here -> gradient accumulation\n","    opt.zero_grad()\n","\n","\n","\n","def all_batches(dl, cb):\n","    for xb,yb in dl:\n","        one_batch(xb, yb, cb)\n","        #we want to execute some process in ceratin condition here after the one batch\n","\n","\n","def fit(epochs, learn, cb):\n","    #we want to execute some process in ceratin condition here before going into training\n","    for epoch in range(epochs):\n","        # self.in_train = True\n","        #we want to execute some process in ceratin condition here in cetain epoch -> not only learn.model.train() also other event \n","        all_batches(learn.data.train_dl, cb)\n","        \n","        \n","        #we want to execute some process in ceratin condition here in before validating -> not only learn.model.eval() also other event \n","        with torch.no_grad(): \n","            # self.in_train = false\n","            all_batches(learn.data.valid_dl, cb)\n","        #we want to execute some process in ceratin condition here in after finishing epoch \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TGlQ6MQBamIQ"},"source":["# skip it\n","\n","## hooks \n","# in the operating system or any applications, changing or interrupting calls/events/message between the software components means hooking\n","# and to do hooking, we use some codes called hook.\n","\n","# delegate \n","# delegation refers generally to one entity passing something to another entity(function or variable), and narrowly to various specific forms of relationships.\n","\n","###"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BukA3yx-Fk68"},"source":["# whole those event codes in fit method makes code messy.\n","# And sometimes those codes may attack or bother the fit processes. So we want handle those event efficiently\n","# At this point, we need something to handle those events independently called callbacks\n","\n","\n","# first set the frame where we want make event in certain condition. That is, partition the point of fit process.\n","# this is callback structure\n","class Callback():\n","    def begin_fit(self, learn):\n","        self.learn = learn\n","        return True\n","    \n","    def after_fit(self): return True\n","    def begin_epoch(self, epoch):\n","        self.epoch=epoch\n","        return True\n","    def begin_validate(self): \n","        return True\n","    def after_epoch(self): return True\n","    def begin_batch(self, xb, yb):\n","        self.xb,self.yb = xb,yb\n","        return True\n","    def after_loss(self, loss):\n","        self.loss = loss\n","        return True\n","    def after_backward(self): return True\n","    def after_step(self): return True\n","\n","# whole returns true bcz if not true they will interrupt the process\n","# and in the literally thinking, system ask to fit process begin_fit ? and say yes."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LswT-0_YPrLt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WT86Z_BTSp_c"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H6RrUBgTFk68"},"source":["# we can change the function with same input and output but different content of function\n","# which is what we want execute when fit process in certain condition\n","class TestCallback(Callback):\n","\n","    def begin_fit(self, learn):\n","        super().begin_fit(learn)\n","        print(f'{\"epoch\":<20}{\"batch\":<20}{\"trainloss\":<40}{\"train_error\":<40}')\n","        return True\n","\n","\n","    def begin_epoch(self,epoch):\n","        super().begin_epoch(epoch)\n","        self.n_iters = 0\n","        print('{:<20}'.format(self.epoch+1),end='')\n","        return True\n","\n","    def begin_batch(self, xb, yb):\n","        super().begin_batch(xb,yb)\n","        self.tot_loss, self.tot_acc = 0,0 \n","        return True\n","\n","    def after_step(self):\n","        self.n_iters += 1\n","        pred = self.learn.model(self.xb)\n","        self.tot_loss = self.learn.loss_func(pred, self.yb.long())\n","        self.tot_acc = accuracy(pred,self.yb)\n","        nv = len(self.yb)\n","        if self.n_iters == 1:\n","            print('{:<20}{:<40}{:<40}'.format(self.n_iters, (self.tot_loss/nv).item(),(self.tot_acc/nv).item()))\n","        else:\n","            print('{:<20}{:<20}{:<40}{:<40}'.format('', self.n_iters, (self.tot_loss/nv).item(),(self.tot_acc/nv).item()))\n","        return True\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kaHR9VeyFk68"},"source":["# we may have lots of callbacks not the only one callback so we need one class more handle the callbacks entirely.\n","# Thats why we need callbackhandler\n","\n","class CallbackHandler():\n","    # get multiple callbacks which is cbs\n","    def __init__(self,cbs=None):\n","        self.cbs = cbs if cbs else []\n","            \n","    def begin_fit(self, learn):\n","        self.learn,self.in_train = learn,True # stick the learn with callbacks.\n","        learn.stop = False\n","        res = True # result\n","        for cb in self.cbs: \n","            res = (res and cb.begin_fit(learn)) \n","\n","        return res\n","\n","    def begin_epoch(self, epoch):\n","        self.learn.model.train()\n","        self.in_train=True\n","        res = True\n","        for cb in self.cbs: \n","            res = res and cb.begin_epoch(epoch)\n","        return res\n","\n","    def begin_batch(self, xb, yb):\n","        res = True\n","        for cb in self.cbs: res = res and cb.begin_batch(xb, yb)\n","        return res\n","\n","    def after_fit(self):\n","        res = not self.in_train\n","        for cb in self.cbs: res = res and cb.after_fit()\n","        return res\n","    \n","\n","    def after_loss(self, loss):\n","        res = self.in_train\n","        for cb in self.cbs: res = res and cb.after_loss(loss)\n","        return res\n","\n","    def after_backward(self):\n","        res = True\n","        for cb in self.cbs: res = res and cb.after_backward()\n","        return res\n","\n","    def after_step(self):\n","        res = True\n","        for cb in self.cbs: \n","            res = res and cb.after_step() # true and something\n","\n","        return res\n","\n","    def do_stop(self):\n","        try:    \n","             return self.learn.stop\n","        finally: \n","            self.learn.stop = False\n","\n","    def begin_validate(self):\n","        self.learn.model.eval()\n","        self.in_train=False\n","        res = True\n","        for cb in self.cbs: res = res and cb.begin_validate()\n","        return res\n","\n","    def after_epoch(self):\n","        res = True\n","        for cb in self.cbs: res = res and cb.after_epoch()\n","        return res\n","    \n","\n","\n","\n","\n","        \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5lVy5KTpFk67"},"source":["# suppose we have only one callback and apply it into batch\n","\n","def one_batch(xb, yb, cb):\n","    if not cb.begin_batch(xb,yb): return\n","\n","    loss = cb.learn.loss_func(cb.learn.model(xb), yb.long())\n","\n","    if not cb.after_loss(loss): return\n","    loss.backward()\n","\n","    if cb.after_backward(): cb.learn.opt.step()\n","\n","    if cb.after_step(): cb.learn.opt.zero_grad()\n","\n","def all_batches(dl, cb):\n","    for (xb,yb) in dl:\n","        one_batch(xb, yb, cb)\n","        if cb.do_stop(): return\n","\n","def fit(epochs, learn, cb):\n","    if not cb.begin_fit(learn): # if begin_fit returns false, interrupt the fit process\n","        return # === return None\n","\n","    for epoch in range(epochs):\n","\n","        if not cb.begin_epoch(epoch): \n","            continue\n","        all_batches(learn.data.train_dl, cb)\n","        \n","        if cb.begin_validate():\n","            with torch.no_grad():\n","                all_batches(learn.data.valid_dl, cb)\n","        if cb.do_stop() or not cb.after_epoch(): \n","            break\n","    cb.after_fit()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nuXfE6t8Fk69"},"source":["fit(2, learn, cb=CallbackHandler([TestCallback()]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"anEbLFopFk69"},"source":["This is roughly how fastai does it now (except that the handler can also change and return `xb`, `yb`, and `loss`). But let's see if we can make things simpler and more flexible, so that a single class has access to everything and can change anything at any time. The fact that we're passing `cb` to so many functions is a strong hint they should all be in the same class!"]},{"cell_type":"markdown","metadata":{"id":"3OJYK5_xFk69"},"source":["## Runner"]},{"cell_type":"markdown","metadata":{"id":"vsx9rYRaFk69"},"source":["[Jump_to lesson 9 video](https://course19.fast.ai/videos/?lesson=9&t=5811)"]},{"cell_type":"code","metadata":{"id":"YEAIkjowUloE"},"source":["# jeremy thinks he can improve his code including \n","# 1. cb input in many function multiple times.\n","# 2. so many duplicate codes in callback\n","# 3. better process than just inherit all things(not forcing all of things to inherit) => if some of function is missed, error will arise\n","\n","# one_batch(xb, yb, cb):  ====> self('event name')\n","# all_batches(dl, cb):       ===> get rid of necessity of keeping state cb.\n","# fit(epochs, learn, cb):\n","\n","\n","# duplicate codes\n","\n","# res = True                                        ====> callback.__call__() : treat object as a function\n","# for cb in self.cbs: res = res and cb.after_epoch()\n","# return res\n","\n","# callbacks becomes super simple than before\n","# class Callback():\n","#     _order=0 # choose the order of callbacks' running \n","#     def set_runner(self, run): \n","#         # print('callback',self,run)\n","#         self.run=run\n","#     def __getattr__(self, k): return getattr(self.run, k) # if python cannot find go into this dunder code\n","#     #@property\n","#     def name(self): # name change\n","#         name = re.sub(r'Callback$', '', self.__class__.__name__)\n","#         return camel2snake(name or 'callback')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVcvP4s5VDt-"},"source":["# He makes new class named runner which is improved version\n","\n","# there is big differencec that former callback returns true in default but now runner's condition is to return false\n","#former\n","# if not cb.begin_batch(xb,yb): return\n","#latter\n","# if self('begin_fit'): return\n","\n","# the reason is that in general function without return returns None which is false. So for preventing mistake or any omittion he changed\n","\n","\n","# \n","# dunder call -> double underline function\n","# __call__, __init__, __getattr__"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s_Cy436CFk6-"},"source":["#export\n","from typing import *\n","\n","\n","## it makes o into list type even if it is string, None, generator\n","def listify(o):\n","    if o is None: return []\n","    if isinstance(o, list): return o\n","    if isinstance(o, str): return [o]\n","    if isinstance(o, Iterable): return list(o)\n","    return [o]\n","\n","# run = Runner(cbs=stats)\n","# run = Runner(cbs=[stats])\n","# run = Runner(cbs=None)\n","# run = Runner(cbs='metric name')\n","# run = Runner(cbs=generator)\n","# all cbs could be handled as list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lmJf8X8jFk6-"},"source":["## runner contains \n","# 1. one batch\n","# 2. all batch\n","# 3. callbackhandlers => __call__ #dunder method == __something__\n","# 4. fit\n","## two types\n","class Runner(): \n","    def __init__(self, cbs=None, cb_funcs=None):\n","        cbs = listify(cbs) # cbs is initialized callback\n","        for cbf in listify(cb_funcs):  # cb_funcs is not the initialized yet\n","            cb = cbf()\n","            setattr(self, cb.name, cb) # automatically sets the callbacks to runner, that is stick together\n","            # print(cb.name)\n","            cbs.append(cb)\n","        self.stop,self.cbs = False,[TrainEvalCallback()]+cbs\n","\n","    @property\n","    def opt(self):       return self.learn.opt\n","    @property\n","    def model(self):     return self.learn.model\n","    @property\n","    def loss_func(self): return self.learn.loss_func\n","    @property\n","    def data(self):      return self.learn.data\n","\n","    def one_batch(self, xb, yb):\n","        self.xb,self.yb = xb,yb\n","        if self('begin_batch'): return\n","        self.pred = self.model(self.xb)\n","        if self('after_pred'): return\n","        self.loss = self.loss_func(self.pred, self.yb.long())\n","        if self('after_loss') or not self.in_train: return  #if not cb.after_loss(loss): return  => we don't need cb\n","        self.loss.backward()\n","        if self('after_backward'): return\n","        self.opt.step()\n","        if self('after_step'): return\n","        self.opt.zero_grad()\n","\n","    def all_batches(self, dl):\n","        self.iters = len(dl)\n","        for xb,yb in dl:\n","            if self.stop: break\n","            self.one_batch(xb, yb)\n","            self('after_batch')\n","        self.stop=False\n","\n","\n","    def fit(self, epochs, learn):\n","        self.epochs,self.learn = epochs,learn #keep track epochs and initialize the learner\n","\n","        try:\n","            for cb in self.cbs: \n","                # print('fit',self)\n","                cb.set_runner(self) #assign runner to callback.run // it makes the callback link to runner(self). -> Callback can use the runner's variables due to __getattr__\n","            if self('begin_fit'): \n","                return  #self('begin_fit') -> runner instance('begin_fit')\n","            for epoch in range(epochs):\n","                self.epoch = epoch\n","                if not self('begin_epoch'): self.all_batches(self.data.train_dl)\n","\n","                with torch.no_grad(): \n","                    if not self('begin_validate'): self.all_batches(self.data.valid_dl)\n","                if self('after_epoch'): break\n","            \n","        finally:\n","            self('after_fit')\n","            self.learn = None\n","\n","    # duplicate callback codes into dunder function\n","    # by this, we need not to input the cb multiple times.\n","    def __call__(self, cb_name):\n","        for cb in sorted(self.cbs, key=lambda x: x._order):\n","            f = getattr(cb, cb_name, None) # if callback's function name doesn't exist in callback, then return None\n","            # if cb_name is not in cb set the cb_name is None\n","            if f and f(): return True\n","        return False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"26ykSBrrOBFx"},"source":["#export\n","import re\n","\n","_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n","_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n","def camel2snake(name):\n","    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n","    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n","\n","# TrainEvalCallback\n","# -> train_eval"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"eY7lnd_OOIKI","executionInfo":{"status":"ok","timestamp":1620888086373,"user_tz":-540,"elapsed":624,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"b0a1fa9e-0cbf-4c71-b216-bd3a1a245b57"},"source":["cbname = 'TrainEvalCallback'\n","camel2snake(cbname)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'train_eval_callback'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"riG4XwsFOIPj","executionInfo":{"status":"ok","timestamp":1620888087068,"user_tz":-540,"elapsed":725,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"92925a62-23c9-459b-8bc6-1c4dc28535cf"},"source":["cbname = ''\n","cbname or 'callback'"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'callback'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"v860hjmIFk69"},"source":["class Callback():\n","    _order=0 # choose the order of callbacks' running \n","    def set_runner(self, run): \n","        # print('callback',self,run)\n","        self.run=run\n","    def __getattr__(self, k): return getattr(self.run, k) # if python cannot find in callback, then go into this dunder code\n","                                                        # callback.run.something  ==> kind of delegate concept\n","    @property\n","    def name(self): # callback class name change into some format\n","        name = re.sub(r'Callback$', '', self.__class__.__name__)\n","        return camel2snake(name or 'callback')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QEDTfjr4Fk69"},"source":["This first callback is reponsible to switch the model back and forth in training or validation mode, as well as maintaining a count of the iterations, or the percentage of iterations ellapsed in the epoch."]},{"cell_type":"code","metadata":{"id":"yEJF8SdbFk6-","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1620888090125,"user_tz":-540,"elapsed":746,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"9dfce826-27d0-4fef-8352-a80d6e7f17a2"},"source":["# most basic callback \n","# they set the basic training loop with tracing the iteration count and epoch count\n","class TrainEvalCallback(Callback): \n","    # _order=0 which is inherited from callback\n","    def begin_fit(self):\n","        self.run.n_epochs=0.\n","        self.run.n_iter=0\n","    \n","    def after_batch(self):\n","        if not self.in_train: return\n","        self.run.n_epochs += 1./self.iters\n","        self.run.n_iter   += 1\n","        \n","    def begin_epoch(self):\n","        self.run.n_epochs=self.epoch\n","        self.model.train()\n","        self.run.in_train=True\n","\n","    def begin_validate(self):\n","        self.model.eval()\n","        self.run.in_train=False\n","TrainEvalCallback().name"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'train_eval'"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"S2Lzik-TFk6-"},"source":["We'll also re-create our TestCallback"]},{"cell_type":"code","metadata":{"id":"OZKlAG-CFk6-"},"source":["class TestCallback(Callback):  \n","    _order = 1 # bcz TestCallback should execute after TrainEvalCallback \n","    def after_step(self):\n","        if self.n_iter>=10: return True # we can use this instead of self.run.n_iter"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MbiyBsZIFk6_"},"source":["Third callback: how to compute metrics."]},{"cell_type":"code","metadata":{"id":"uk_62aCHFk6_"},"source":["\n","class AvgStats():\n","    def __init__(self, metrics, in_train):\n","         self.metrics,self.in_train = listify(metrics),in_train\n","    \n","    def reset(self):\n","        self.tot_loss,self.count = 0.,0\n","        # print('metrics',len(self.metrics))\n","        self.tot_mets = [0.] * len(self.metrics) # [0.] duplicate by len(self.metrics)\n","        # print('tot_mets',self.tot_mets)\n","\n","    @property\n","    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets # loss and accuracy\n","    @property\n","    def avg_stats(self): return [o/self.count for o in self.all_stats] # get the mean of metrics\n","    \n","    def __repr__(self):\n","        if not self.count: return \"\"\n","        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n","\n","    def accumulate(self, run):\n","        bn = run.xb.shape[0] # 64,784\n","        self.tot_loss += run.loss * bn # loss total(summation of loss) / batch size = run.loss\n","        self.count += bn\n","        for i,m in enumerate(self.metrics):\n","            #\n","            self.tot_mets[i] += m(run.pred, run.yb) * bn\n","\n","# 1 batch 1 get loss one batch\n","# accumulate\n","# total loss      count.  tot_loss\n","# 1batch loss. // 64.     1batch\n","# 1batch loss. // 128.    1batch + 1batch\n","# 1batch loss. // 192.     1batch + 1batch + 1batch loss\n","\n","\n","class AvgStatsCallback(Callback):\n","    def __init__(self, metrics):\n","        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n","        \n","    # initialize the metric and loss parameters as soon as epoch starts\n","    def begin_epoch(self):\n","        self.train_stats.reset()\n","        self.valid_stats.reset()\n","    \n","    # if training loop, use train_stats. If validating loop, use valid_stats\n","    def after_loss(self):\n","        stats = self.train_stats if self.in_train else self.valid_stats\n","        with torch.no_grad(): stats.accumulate(self.run)\n","        \n","    # after each epoch, print the loss and accuracy\n","    def after_epoch(self):\n","        print(self.train_stats)\n","        print(self.valid_stats)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6C1uzaytFk6_"},"source":["learn = Learner(*get_model(data), loss_func, data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"77hxiwr-Fk6_"},"source":["stats = AvgStatsCallback([accuracy])\n","run = Runner(cbs=stats)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a21SQDCNFk6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620888868109,"user_tz":-540,"elapsed":4727,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"0a989eb7-37da-4731-c0f0-56d2fcbba14d"},"source":["run.fit(4, learn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train: [0.138389296875, tensor(0.9582)]\n","valid: [0.496626416015625, tensor(0.8675)]\n","train: [0.105518388671875, tensor(0.9682)]\n","valid: [0.10035296630859375, tensor(0.9693)]\n","train: [0.0863809765625, tensor(0.9727)]\n","valid: [0.113865478515625, tensor(0.9658)]\n","train: [0.0729070751953125, tensor(0.9771)]\n","valid: [0.2067080322265625, tensor(0.9445)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HWrxYUxYFk6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620888870400,"user_tz":-540,"elapsed":600,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"afc8bfad-36f4-46c2-e856-1fde1cf04b5b"},"source":["loss,acc = stats.valid_stats.avg_stats\n","assert acc>0.9\n","loss,acc"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.2067080322265625, tensor(0.9445))"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"VVF0XSGGfWTq"},"source":["# with this process, we have something to improve \n","# it is awkward to deal with a callback instance and metric independenlty. so we can put metrics into the runner class then refer to the runner.something not stats.something\n","# so we can merge whole processes into one instance\n","# that is why there is cb_func parameter for runner."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OI1HHXbsFk7A"},"source":["# \n","from functools import partial\n","## https://hamait.tistory.com/823 partial example\n","\n","# what is partial?\n","\n","# def power(base, exponent):\n","#     return base ** exponent\n","\n","# def square(base):                    => partial(power,exponent=2)\n","#     return power(base, 2)\n","\n","# def cube(base):                       => partial(power,exponent=3)\n","#     return power(base, 3)\n","\n","# function returns function"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9el3Pf0VFk7C"},"source":["acc_cbf = partial(AvgStatsCallback,accuracy)\n","\n","# class AvgStatsCallback(Callback):\n","#     def __init__(self, metrics = accuracy):\n","#         self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gHcyTqYFk7C"},"source":["run = Runner(cb_funcs=acc_cbf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xGGYu7eiFk7C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620889170074,"user_tz":-540,"elapsed":1849,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"43e4df72-4bde-4687-bb63-b71a5d15ad26"},"source":["run.fit(1, learn)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train: [0.0632914892578125, tensor(0.9797)]\n","valid: [0.2720301025390625, tensor(0.9248)]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3hgd5U3bFk7C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620712887004,"user_tz":-540,"elapsed":1251,"user":{"displayName":"Hyukhun Koh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjFmQFILEivwghVAUWhEtg_t_piycJmb4VOpPQS=s64","userId":"04457846064668801006"}},"outputId":"2deead54-b479-40cc-8624-c2edae22cdd1"},"source":["#using cb.name in runner\n","# AvgStatsCallback -> avg_stats by name function and set in the runner\n","# then stick to runner with that name.\n","run.avg_stats.valid_stats.avg_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.15419449462890625, tensor(0.9538)]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"AE72dPYXFk7D"},"source":["## Export"]},{"cell_type":"code","metadata":{"id":"PRB2x_MKFk7D","outputId":"80e694df-7038-4411-bad7-0ec5e92f7371"},"source":["!python notebook2script.py 04_callbacks.ipynb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Converted 04_callbacks.ipynb to nb_04.py\r\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V_hFISgFFk7D"},"source":[""],"execution_count":null,"outputs":[]}]}